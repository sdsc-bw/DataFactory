{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sdsc-bw/DataFactory/blob/develop/demos/02_Feature_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Conceptually, feature engineering is a process that transforms data into features that can better represent business logic, thereby improving the performance of machine learning.\n",
    "\n",
    "<img src = '../images/fe_pipeline.png'>\n",
    "\n",
    "As shown in the figure above, it is an important step in data mining. In fact, it is also the most time-consuming <a href = https://whatsthebigdata.com/2016/05/01/data-scientists-spend-most-of-their-time-cleaning-data/> Data Scientists Spend Most of Their Time Cleaning Data </a>.\n",
    "\n",
    "<img src = '../images/pie.png'>\n",
    "\n",
    "In this demo we show different transformations and how you can use them in the datafactory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How To use in the Datafactory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:05:08.702131Z",
     "start_time": "2021-07-06T14:05:07.315194Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    ! git clone https://github.com/sdsc-bw/DataFactory.git # clone repository for colab\n",
    "    ! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings # igorne irrelevant warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:14.494576Z",
     "start_time": "2021-07-06T14:06:14.486851Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sktime.utils.data_io'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13980/921992508.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatafactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_engineering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms_binary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;31m# binary transformations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdatafactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_engineering\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforming\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;31m# transforming methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatafactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_plotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplot_density_for_each_column_in_df\u001b[0m \u001b[1;31m# density visualization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatafactory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[1;31m# method to evaluate the dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\HiWi Job\\DataFactory\\demos\\..\\datafactory\\ts\\feature_engineering\\transforming.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtransforms_binary\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtransforms_multi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtransforms_transform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\HiWi Job\\DataFactory\\demos\\..\\datafactory\\ts\\feature_engineering\\transforms_transform.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../../util'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m...\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mData_rb_cla\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mData_rb_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMLP\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetaclass\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mABCMeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\HiWi Job\\DataFactory\\demos\\..\\datafactory\\util\\datasets.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mTS_DATASETS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'iris'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wine'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'diabetes'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'breast_cancer'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\HiWi Job\\DataFactory\\demos\\..\\datafactory\\util\\transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtsai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\datafactorycpu\\lib\\site-packages\\tsai\\all.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mimports\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\datafactorycpu\\lib\\site-packages\\tsai\\data\\all.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpreparation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mexternal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0munwindowed\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\datafactorycpu\\lib\\site-packages\\tsai\\data\\external.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# Cell\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msktime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_io\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_from_tsfile_to_dataframe\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mts2df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msktime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpanel\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcheck_X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msktime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_io\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTsFileParseException\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sktime.utils.data_io'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt # library used for visualization\n",
    "import numpy as np # library for efficient list calculations\n",
    "import pandas as pd # library for creating tables\n",
    "import seaborn as sns # library for plotting statistical data visualization\n",
    "from abc import ABCMeta, abstractmethod # library to create abstract methods\n",
    "from sklearn.preprocessing import LabelEncoder # method to encode features\n",
    "from sklearn.model_selection import train_test_split # method to split data into training and test data and seperate data and targets\n",
    "\n",
    "## add path to import datafactory \n",
    "if 'google.colab' in sys.modules: \n",
    "    root = 'DataFactory/'\n",
    "else:\n",
    "    root = '../'\n",
    "sys.path.append(root)\n",
    "\n",
    "from datafactory.ts.feature_engineering.transforms_binary import * # binary transformations\n",
    "from datafactory.ts.feature_engineering.transforming import * # transforming methods\n",
    "from datafactory.ts.plotting.dataset_plotting import plot_density_for_each_column_in_df # density visualization\n",
    "from datafactory.ts.preprocessing.loading import evaluate # method to evaluate the dataset\n",
    "from datafactory.ts.preprocessing.cleaning import clean_data # method to clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test dataset: diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href = 'https://www.openml.org/d/37'> Diabets</a> is an open source data set on OpenCV. It collected the physical conditions of a total of 768 residents living in Phoenix, Arizona, USA. These information include:\n",
    "- Number of times pregnant\n",
    "- Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "- Diastolic blood pressure (mm Hg)\n",
    "- Triceps skin fold thickness (mm)\n",
    "- 2-Hour serum insulin (mu U/ml)\n",
    "- Body mass index (weight in kg/(height in m)^2)\n",
    "- Diabetes pedigree function\n",
    "- Age (years)\n",
    "- Has diabet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:16.247564Z",
     "start_time": "2021-07-06T14:06:16.231865Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(root + 'data/dataset_37_diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:18.098451Z",
     "start_time": "2021-07-06T14:06:18.071699Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the prediction target is of the character type, which cannot be processed by most models, so we first convert it to a numeric type with labelencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:20.049819Z",
     "start_time": "2021-07-06T14:06:20.027003Z"
    }
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['class'] = le.fit_transform(df['class'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Depending on whether the transformation requires the use of the target value ('class' in the diabetes example), transformations for feature engineering can be distinguished into supervised and unsupervised transformations. And depending on the number of input attributes per conversion unsupervised conversions can again be classified as unary, binary and multivariate conversions.\n",
    "<img src = '../images/transform.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T15:23:21.605297Z",
     "start_time": "2021-06-29T15:23:21.583525Z"
    }
   },
   "source": [
    "## Unsupervised Transformation\n",
    "### Unary Feature transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-29T15:58:03.376916Z",
     "start_time": "2021-06-29T15:58:03.296143Z"
    }
   },
   "source": [
    "<img width=\"350\" height=\"360\" src = '../images/unary.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:24.123848Z",
     "start_time": "2021-07-06T14:06:24.118672Z"
    }
   },
   "outputs": [],
   "source": [
    "class UnaryOpt(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def fit(self, value: pd.Series) -> pd.Series:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All unary transform are wrapped as a subclass of 'UnaryOpt', which has one fix function 'fit'. Following is a brief introduction and demonstration of the unary conversion\n",
    "* abs: |x|\n",
    "* add: x + e\n",
    "* negative: -x\n",
    "* log: log(x)\n",
    "* exp: e^x\n",
    "* reciprocol: 1/x\n",
    "* square: x*x\n",
    "* squrt: \n",
    "* cos: cos(x)\n",
    "* sin: sin(x)\n",
    "* degree: Convert angles from radians to degrees\n",
    "* radians: Convert angles from degrees to radians\n",
    "* sigmoid: 1 / (1 + exp(-x))\n",
    "* tanh: sinh(x)/cosh(x)\n",
    "* relu: x * (x > 0)\n",
    "* binning: clustering for a single feature\n",
    "* ktermfreq: value counts\n",
    "\n",
    "To simplify the programming, sdsc researchers developed the DataFactory class (the specifics of this class will be described in other notebooks), which can finish all the unary transformation in one function.\n",
    "- apply_unary_transformations_to_series(self, value: pd.Series) -> pd.DataFrame\n",
    "    - It takes a series (feature) as input and output a dataframe after the transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:27.522378Z",
     "start_time": "2021-07-06T14:06:27.233882Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = apply_unary_transforms_to_series(df['preg'])\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One noteworthy thing is that feature transformation can lead to the generation of implausible values, such as the fifth value of log(preg) in the table above. Since the original value is 0, the corresponding log value is negative infinity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few plots show the density distribution of the attributes before and after the conversion, and we can see that their density distribution functions show a big difference, and this is the main reason for our conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:30.210009Z",
     "start_time": "2021-07-06T14:06:29.884704Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,6))\n",
    "sns.kdeplot(df['preg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:35.594389Z",
     "start_time": "2021-07-06T14:06:31.058806Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_density_for_each_column_in_df(tmp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary feature transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"350\" height=\"360\" src = '../images/binary.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:35.606714Z",
     "start_time": "2021-07-06T14:06:35.599758Z"
    }
   },
   "outputs": [],
   "source": [
    "class BinaryOpt(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def fit(self, value1: pd.Series, value2: pd.Series) -> pd.Series:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All unary transform are wrapped as a subclass of 'BinaryOpt', which has one fix function 'fit'. It takes two series as input and output the series after transformation. There are only four binary transformation defiend in DataFactory class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:38.485219Z",
     "start_time": "2021-07-06T14:06:38.479269Z"
    }
   },
   "outputs": [],
   "source": [
    "operators = {'div': Div(), 'minus': Minus(), 'add': Add(), 'product': Product()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:40.305726Z",
     "start_time": "2021-07-06T14:06:40.255343Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_df = apply_binary_transforms_to_series(df['preg'], df['plas'])\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple feature transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"650\" height=\"660\" src = '../images/multiple.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All unary transform are wrapped as a subclass of 'MultiOpt', which also has one fix function 'fit'. The multivariate transformation takes several different features as input (generally the whole dataset) and its output generally contains one or more different features in form of DataFrame. The transformation functions can be broadly classified into clustering, regularization, downscaling and time series attribute extraction. At present, SDSC researchers do not implement all possible transformation methods, for example, for the clustering method category only Kmeans is implemented, while other common clusters are not implemented.\n",
    "\n",
    "- Clustering: \n",
    "    - clustering the data set with Kmeans and use the result as new feature.\n",
    "    - Because most, datasets contain dozens of features, and kmeans does not perform well on high-dimensional data, SDSC staff incorporates a sliding window mechanism in clustering, where values are clustered only for features in the same window.\n",
    "- Normalization:\n",
    "    - minmax \n",
    "    - zscore\n",
    "- Dimension_reduction:\n",
    "    - isomap\n",
    "- Time_series feature extraction: each item in the dataset is treated as a time series\n",
    "    - Diff: diff between the columns\n",
    "    - WinAgg\n",
    "        - apply sliding window to it and aggregate\n",
    "        - agg func include: max, .25, .50, .75, max, std\n",
    "- Other:\n",
    "    - LeakyInfo\n",
    "    - KernelApproxRBF: use rbf to approximate kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:45.281374Z",
     "start_time": "2021-07-06T14:06:45.275235Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiOpt(metaclass=ABCMeta):\n",
    "    @abstractmethod\n",
    "    def fit(self, df: pd.DataFrame):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:06:49.099211Z",
     "start_time": "2021-07-06T14:06:46.514000Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_df = apply_multiple_transforms_to_dataframe(df.iloc[:, :-1])\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T08:32:06.942518Z",
     "start_time": "2021-07-01T08:32:06.900841Z"
    }
   },
   "source": [
    "## Supervised Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This category is more complex and it mainly uses some existing models, such as decision trees, k-nearest neighbors, etc., to assist in generating new features. Depending on the type of dataset, it can be broadly classified into two main types: classification and regression.\n",
    "\n",
    "Another special feature of this classification is that since the target value of the test set is unknown, there is no way to generate new features purely by relying on the test set. The composition of the features in the test set depends on the model built in the training set.\n",
    "\n",
    "Taking DecisionTreeClassifier for example, following three information can be extracted:\n",
    "- regard each node in the last layer of the tree as a cluster, extract the clustering information\n",
    "- use the prediction of the model\n",
    "- compute the distance between the predictt and ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:07:14.392193Z",
     "start_time": "2021-07-06T14:06:51.298979Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1])\n",
    "tmp_df, tmp_df2 = apply_supervised_transforms_to_dataframe(X_train, X_test, y_train, y_test, 'C')\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:07:24.420346Z",
     "start_time": "2021-07-06T14:07:14.398353Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1])\n",
    "tmp_df, tmp_df2 = apply_supervised_transforms_to_dataframe(X_train, X_test, y_train, y_test, 'R')\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only Apply Certain Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To only apply certain transformations, insert the dataframe and the transformations as list together with the column names where to apply the transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trfms = [('ln', 'age'), ('cos', 'age'), ('exp', 'skin'), ('add', 'pres', 'age'), ('minmaxnorm', 'insu', 'mass', 'age'), 'dfCla']\n",
    "tmp_df = apply_transforms(df, trfms)\n",
    "tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate\n",
    "In this section we will briefly test the effect of the feature engineering by comparing the accuracy before and after using the transformation.\n",
    "\n",
    "Meanwhile, SDSC engineers have integrated the evaluate method in the data factory. This method uses the data and the predicted target as input and outputs the corresponding cv results: weighted f1 score for classification task and 1-rae for regression task.\n",
    "\n",
    "It is worth noting that we only use multivariate transformation once in this test. In addition, there may generate na or inf values after transformation, which we will handle using the clean_data method in the data factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:07:30.560105Z",
     "start_time": "2021-07-06T14:07:29.219511Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(df.iloc[:, :-1], df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:07:35.026062Z",
     "start_time": "2021-07-06T14:07:33.389088Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_multi = apply_multiple_transforms_to_dataframe((df.iloc[:, :-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:07:35.125475Z",
     "start_time": "2021-07-06T14:07:35.043609Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([tmp_multi, df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:07:35.379714Z",
     "start_time": "2021-07-06T14:07:35.158257Z"
    }
   },
   "outputs": [],
   "source": [
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T14:07:49.680474Z",
     "start_time": "2021-07-06T14:07:47.933263Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(df.iloc[:, :-1], df.iloc[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By comparing the results we find that there is a significant improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datafactorycpu",
   "language": "python",
   "name": "datafactorycpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

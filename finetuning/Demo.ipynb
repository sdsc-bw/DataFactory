{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e4cdb8",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sdsc-bw/DataFactory/blob/develop/finetuning/Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fe1f22",
   "metadata": {},
   "source": [
    "# Finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7d63d5",
   "metadata": {},
   "source": [
    "To find a suitable model for your ML problem is very important. Not every model has the same performane on every task. Some models can be to simple (underfitting) and some models can be to complex for for a problem (overfitting). Also a model has different hyperparameters which also have an impact on the performance. Therefor exist libraries that can be used to find a appropriate model and its hyperparameters. Popular ones are [auto-sklearn](https://github.com/automl/auto-sklearn) and [hyperopt](https://github.com/hyperopt/hyperopt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8205e07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'finetuning'...\n",
      "remote: Repository not found.\n",
      "fatal: repository 'https://github.com/sdsc-bw/finetuning.git/' not found\n",
      "Der Befehl \"ls\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/sdsc-bw/finetuning.git\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8364c25",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cef7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9289706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_wine, load_digits\n",
    "from hyperopt import hp\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, root + \"codes\")\n",
    "from DataFactory import DataFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a0a167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9259c4c0",
   "metadata": {},
   "source": [
    "## Load dataset: MNIST digit dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0eb83d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c70b473",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X[0].reshape(8, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3982abb1",
   "metadata": {},
   "source": [
    "## Load dataset: wine dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a923486",
   "metadata": {},
   "source": [
    "The third dataset is the [wine dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) from sklearn. It contains the follwing information:\n",
    "- 13 features\n",
    "- 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0e5aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "df_wine = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df_wine['class'] = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "323235e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  class  \n",
       "0                          3.92   1065.0      0  \n",
       "1                          3.40   1050.0      0  \n",
       "2                          3.17   1185.0      0  \n",
       "3                          3.45   1480.0      0  \n",
       "4                          2.93    735.0      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# needs no prepocessing\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527d1d73",
   "metadata": {},
   "source": [
    "## Use DataFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec311175",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafactory = DataFactory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef5fbef",
   "metadata": {},
   "source": [
    "### Auto-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326ab775",
   "metadata": {},
   "source": [
    "Auto-sklearn requires a linux OS (otherwise it can be run on colab). It is an automated machine learning toolkit using sklearn models. It automatically trains different ML models with different hyperparameters. At the end it selects the best model. In the DataFactory you can use it like that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2de3192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model, score = datafactory.finetune(X, y, strategy='auto_sklearn', mtype='C')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612271e",
   "metadata": {},
   "source": [
    "### Sklearn with Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a96a3b",
   "metadata": {},
   "source": [
    "Sklearn also provides functions to tune the hyperparameters for a specific model. We implemented a function to also find the best model:\n",
    "\n",
    "We can define the models that we want to test. Then we have to define a *param* variable that defines the strategy how to examine the search space. There we also can define the parameters of the search space. If parameters for models are not given, it uses the standard search space. Like we do it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56cfafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with models to try out\n",
    "models = ['decision_tree', 'random_forest', 'adaboost']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52cb31c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 13:52:31,540 - DataFactory - INFO - Start finetuning...\n",
      "2021-11-22 13:52:31,541 - DataFactory - INFO - Start search for best parameters of: decision_tree...\n",
      "2021-11-22 13:52:33,029 - DataFactory - INFO - ...End search\n",
      "2021-11-22 13:52:33,030 - DataFactory - INFO - Best parameters are: {'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 9, 'criterion': 'gini'} with score 0.85\n",
      "2021-11-22 13:52:33,030 - DataFactory - INFO - Start search for best parameters of: random_forest...\n",
      "2021-11-22 13:52:36,246 - DataFactory - INFO - ...End search\n",
      "2021-11-22 13:52:36,246 - DataFactory - INFO - Best parameters are: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10} with score 0.97\n",
      "2021-11-22 13:52:36,247 - DataFactory - INFO - Start search for best parameters of: adaboost...\n",
      "2021-11-22 13:52:40,742 - DataFactory - INFO - ...End search\n",
      "2021-11-22 13:52:40,742 - DataFactory - INFO - Best parameters are: {'n_estimators': 200, 'learning_rate': 0.01} with score 0.77\n",
      "2021-11-22 13:52:40,743 - DataFactory - INFO - ...End finetuning\n",
      "2021-11-22 13:52:40,744 - DataFactory - INFO - Best model is: random_forest with parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 50, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "model, score = datafactory.finetune(X, y, strategy='sklearn', models=models, cv=5, mtype='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36e59a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9711640387431736"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9731807",
   "metadata": {},
   "source": [
    "Here we defined a custom search space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "932d113c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with params for every model to try out (search strategy of hyperparameters should be in ['grid', 'random'])\n",
    "params = {'strategy': 'random', 'decision_tree': {\"criterion\": ['gini', 'entropy'], \"max_depth\": range(1, 50), \"min_samples_split\": range(1, 20), \"min_samples_leaf\": range(1, 5)}, 'random_forest': {'max_depth': [1, 2, 3, 5, 10, 20, 50], 'min_samples_leaf': [1, 5, 10], 'min_samples_split': [2, 5, 10], 'n_estimators': [50, 100, 200]}, 'adaboost': {'n_estimators': [50, 100, 200], 'learning_rate':[0.001,0.01,.1]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "851c456c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 13:52:40,781 - DataFactory - INFO - Start finetuning...\n",
      "2021-11-22 13:52:40,782 - DataFactory - INFO - Start search for best parameters of: decision_tree...\n",
      "2021-11-22 13:52:40,981 - DataFactory - INFO - ...End search\n",
      "2021-11-22 13:52:40,981 - DataFactory - INFO - Best parameters are: {'min_samples_split': 3, 'min_samples_leaf': 1, 'max_depth': 28, 'criterion': 'entropy'} with score 0.86\n",
      "2021-11-22 13:52:40,982 - DataFactory - INFO - Start search for best parameters of: random_forest...\n",
      "2021-11-22 13:52:44,052 - DataFactory - INFO - ...End search\n",
      "2021-11-22 13:52:44,053 - DataFactory - INFO - Best parameters are: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 10} with score 0.97\n",
      "2021-11-22 13:52:44,053 - DataFactory - INFO - Start search for best parameters of: adaboost...\n",
      "2021-11-22 13:52:48,413 - DataFactory - INFO - ...End search\n",
      "2021-11-22 13:52:48,414 - DataFactory - INFO - Best parameters are: {'n_estimators': 200, 'learning_rate': 0.1} with score 0.83\n",
      "2021-11-22 13:52:48,414 - DataFactory - INFO - ...End finetuning\n",
      "2021-11-22 13:52:48,414 - DataFactory - INFO - Best model is: random_forest with parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 10, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "model, score = datafactory.finetune(X, y, strategy='sklearn', models=models, cv=5, mtype='C', params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34ddd540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9711259969722548"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5253ff",
   "metadata": {},
   "source": [
    "### Hyperopt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100cca6b",
   "metadata": {},
   "source": [
    "We also can provide a function to use hyperopt. It can be used the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "515994ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with models to try out\n",
    "models = ['decision_tree']\n",
    "# list with params for every model to try out (search strategy of hyperparameters should be in ['parzen', 'random'])\n",
    "params = {'strategy': 'random'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "da3da630",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 13:52:48,466 - DataFactory - INFO - Start finetuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{classifier_type}\n",
      "3     randint\n",
      "4       Literal{1}\n",
      "5   dict\n",
      "6    criterion =\n",
      "7     switch\n",
      "8       hyperopt_param\n",
      "9         Literal{criterion}\n",
      "10         randint\n",
      "11           Literal{2}\n",
      "12       Literal{gini}\n",
      "13       Literal{entropy}\n",
      "14    cv =\n",
      "15     Literal{3}\n",
      "16    max_depth =\n",
      "17     float\n",
      "18       hyperopt_param\n",
      "19         Literal{max_depth}\n",
      "20         quniform\n",
      "21           Literal{1}\n",
      "22           Literal{10}\n",
      "23           Literal{1}\n",
      "24    min_samples_leaf =\n",
      "25     switch\n",
      "26       hyperopt_param\n",
      "27         Literal{min_samples_leaf}\n",
      "28         randint\n",
      "29           Literal{3}\n",
      "30       Literal{1}\n",
      "31       Literal{2}\n",
      "32       Literal{4}\n",
      "33    min_samples_split =\n",
      "34     switch\n",
      "35       hyperopt_param\n",
      "36         Literal{min_samples_split}\n",
      "37         randint\n",
      "38           Literal{3}\n",
      "39       Literal{2}\n",
      "40       Literal{3}\n",
      "41       Literal{5}\n",
      "42    model =\n",
      "43     Literal{decision_tree}\n",
      "44    type =\n",
      "45     Literal{C}\n",
      "100%|███████████████████████████████████████████████| 32/32 [00:01<00:00, 29.69trial/s, best loss: -0.7757373400111297]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 13:52:49,754 - DataFactory - INFO - ...End finetuning\n",
      "2021-11-22 13:52:49,754 - DataFactory - INFO - Best model is: decision_tree with parameters: {'criterion': 'gini', 'max_depth': 9.0, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, score = datafactory.finetune(X, y, strategy='hyperopt', models=models, cv=3, mtype='C', params=params.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "45578809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7757373400111297"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2265eb63",
   "metadata": {},
   "source": [
    "If we want to define custom parameters, they should be defined with the functions of hyperopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b60853f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['decision_tree']\n",
    "params = {'strategy': 'random', 'decision_tree': {'max_depth': hp.quniform('max_depth', 1, 10, 1), 'criterion': hp.choice('criterion', ['gini', 'entropy']), 'min_samples_leaf': hp.choice('min_samples_leaf', [1, 2, 4])}, 'random_forest': {'max_depth': hp.choice('max_depth', [1, 2, 3, 5, 10, 20, 50]), 'n_estimators': hp.choice('n_estimators', [50, 100, 200])}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3676483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 13:52:49,793 - DataFactory - INFO - Start finetuning...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 switch\n",
      "1   hyperopt_param\n",
      "2     Literal{classifier_type}\n",
      "3     randint\n",
      "4       Literal{1}\n",
      "5   dict\n",
      "6    criterion =\n",
      "7     switch\n",
      "8       hyperopt_param\n",
      "9         Literal{criterion}\n",
      "10         randint\n",
      "11           Literal{2}\n",
      "12       Literal{gini}\n",
      "13       Literal{entropy}\n",
      "14    cv =\n",
      "15     Literal{5}\n",
      "16    max_depth =\n",
      "17     float\n",
      "18       hyperopt_param\n",
      "19         Literal{max_depth}\n",
      "20         quniform\n",
      "21           Literal{1}\n",
      "22           Literal{10}\n",
      "23           Literal{1}\n",
      "24    min_samples_leaf =\n",
      "25     switch\n",
      "26       hyperopt_param\n",
      "27         Literal{min_samples_leaf}\n",
      "28         randint\n",
      "29           Literal{3}\n",
      "30       Literal{1}\n",
      "31       Literal{2}\n",
      "32       Literal{4}\n",
      "33    model =\n",
      "34     Literal{decision_tree}\n",
      "35    type =\n",
      "36     Literal{C}\n",
      "100%|███████████████████████████████████████████████| 32/32 [00:01<00:00, 16.11trial/s, best loss: -0.8058000619003405]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 13:52:51,820 - DataFactory - INFO - ...End finetuning\n",
      "2021-11-22 13:52:51,821 - DataFactory - INFO - Best model is: decision_tree with parameters: {'criterion': 'entropy', 'max_depth': 9.0, 'min_samples_leaf': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model, score = datafactory.finetune(X, y, strategy='hyperopt', models=models, cv=5, mtype='C', params=params.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9e16290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8058000619003405"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f795c544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datafactory",
   "language": "python",
   "name": "datafactory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

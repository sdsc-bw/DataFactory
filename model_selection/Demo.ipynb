{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e4cdb8",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sdsc-bw/DataFactory/blob/develop/model_selection/Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b807f0b1",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f1464",
   "metadata": {},
   "source": [
    "There is a variety of models that can be used in machine learning like decision trees, random forests, neural networks...\n",
    "Depending on the problem we have many different models to choose from. Here a small overview of the most common:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988103f",
   "metadata": {},
   "source": [
    "<img src=\"../images/model_selection.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9961a5ac",
   "metadata": {},
   "source": [
    "If have labeled training data we can choose between different many different supervised methods. Whereas if we don't have the labels, the we have to use unsupervised methods like clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf3fa2",
   "metadata": {},
   "source": [
    "Also according to the problem, some models fit better than others. For example, for a simple problem it makes sense to use a more simple model like a decision tree, because more complex models like neural networks can lead to overfitting. Whereas these complexe models perform better at non-linear problems. In this notebook we want to show some models and how they perform on different tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f0c18d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'model_selection'...\n",
      "remote: Repository not found.\n",
      "fatal: repository 'https://github.com/sdsc-bw/model_selection.git/' not found\n",
      "Der Befehl \"ls\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "! git clone https://github.com/sdsc-bw/model_selection.git\n",
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913adc23",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54962dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ebd2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.datasets import load_iris, load_wine, fetch_covtype\n",
    "import sys\n",
    "sys.path.insert(0, root + \"codes\")\n",
    "\n",
    "from DataFactory import DataFactory\n",
    "from util import compare_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "515ec6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f40fdc5",
   "metadata": {},
   "source": [
    "## Titanic dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6116cd79",
   "metadata": {},
   "source": [
    "The first dataset is the [titanic dataset](https://www.kaggle.com/c/titanic-dataset/data) from kaggle. It contains the follwing information:\n",
    "- __passenger_id__ unique identifier for each passenger\n",
    "- __pclass__ class of the passenger  (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "- __name__ name of the passenger\n",
    "- __sex__ sex of the passenger\n",
    "- __age__ age of the passenger in years\n",
    "- __sibsp__ number of siblings/souses aboard\n",
    "- __parch__ number of parents/children aboard\n",
    "- __ticket__ number of the ticket\n",
    "- __fare__ passenger fare in British pound\n",
    "- __cabin__ cabin of the passenger\n",
    "- __embarked__ port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "- __boat__ Lifeboat\n",
    "- __body__ body identification number\n",
    "- __home.dest__ Home/Destination\n",
    "- __survived__ wether the person survived "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a4bcf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titanic = pd.read_csv('../data/titanic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28960896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>pclass</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1216</td>\n",
       "      <td>3</td>\n",
       "      <td>Smyth, Miss. Julia</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>335432</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>699</td>\n",
       "      <td>3</td>\n",
       "      <td>Cacic, Mr. Luka</td>\n",
       "      <td>male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315089</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Croatia</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1267</td>\n",
       "      <td>3</td>\n",
       "      <td>Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>345773</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449</td>\n",
       "      <td>2</td>\n",
       "      <td>Hocking, Mrs. Elizabeth (Eliza Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29105</td>\n",
       "      <td>23.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cornwall / Akron, OH</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576</td>\n",
       "      <td>2</td>\n",
       "      <td>Veal, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28221</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Barre, Co Washington, VT</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  pclass                                               name  \\\n",
       "0          1216       3                                 Smyth, Miss. Julia   \n",
       "1           699       3                                    Cacic, Mr. Luka   \n",
       "2          1267       3  Van Impe, Mrs. Jean Baptiste (Rosalie Paula Go...   \n",
       "3           449       2              Hocking, Mrs. Elizabeth (Eliza Needs)   \n",
       "4           576       2                                    Veal, Mr. James   \n",
       "\n",
       "      sex   age  sibsp  parch  ticket     fare cabin embarked boat  body  \\\n",
       "0  female   NaN      0      0  335432   7.7333   NaN        Q   13   NaN   \n",
       "1    male  38.0      0      0  315089   8.6625   NaN        S  NaN   NaN   \n",
       "2  female  30.0      1      1  345773  24.1500   NaN        S  NaN   NaN   \n",
       "3  female  54.0      1      3   29105  23.0000   NaN        S    4   NaN   \n",
       "4    male  40.0      0      0   28221  13.0000   NaN        S  NaN   NaN   \n",
       "\n",
       "                  home.dest  survived  \n",
       "0                       NaN       1.0  \n",
       "1                   Croatia       0.0  \n",
       "2                       NaN       0.0  \n",
       "3      Cornwall / Akron, OH       1.0  \n",
       "4  Barre, Co Washington, VT       0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7816de",
   "metadata": {},
   "source": [
    "There we can see that there are many attributes with many missing values. As in the demo before, we have to preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf39e4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 18:39:19,919 - DataFactory - INFO - Remove columns with NAN-values of target feature: survived\n",
      "2021-11-16 18:39:19,924 - DataFactory - INFO - Start to transform the categorical columns...\n",
      "2021-11-16 18:39:19,931 - DataFactory - INFO - Start with one-hot encoding of the following categoric features: ['sex', 'embarked']...\n",
      "2021-11-16 18:39:19,933 - DataFactory - INFO - ...End with one-hot encoding\n",
      "2021-11-16 18:39:19,934 - DataFactory - INFO - Start label encoding of the following categoric features: ['name', 'ticket', 'cabin', 'boat', 'home.dest']...\n",
      "2021-11-16 18:39:19,942 - DataFactory - INFO - ...End with label encoding\n",
      "2021-11-16 18:39:19,944 - DataFactory - INFO - ...End with categorical feature transformation\n",
      "2021-11-16 18:39:19,945 - DataFactory - INFO - Start to clean the given dataframe...\n",
      "2021-11-16 18:39:19,950 - DataFactory - INFO - Number of INF- and NAN-values are: (0, 952)\n",
      "2021-11-16 18:39:19,950 - DataFactory - INFO - Set type to float32 at first && deal with INF\n",
      "2021-11-16 18:39:19,952 - DataFactory - INFO - Remove columns with half of NAN-values\n",
      "2021-11-16 18:39:19,954 - DataFactory - INFO - Remove constant columns\n",
      "2021-11-16 18:39:19,957 - DataFactory - INFO - Start to fill the columns with NAN-values...\n",
      "2021-11-16 18:39:20,083 - DataFactory - INFO - ...End with Data cleaning, number of INF- and NAN-values are now: (0, 0)\n"
     ]
    }
   ],
   "source": [
    "datafactory = DataFactory()\n",
    "dfx_titanic, dfy_titanic = datafactory.preprocess(df_titanic, y_col='survived')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738da142",
   "metadata": {},
   "source": [
    "## Load dataset: iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729074a7",
   "metadata": {},
   "source": [
    "The second dataset is the [iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) from sklearn. It contains the follwing information:\n",
    "- __sepal length__ sepal length of the iris in cm\n",
    "- __sepal width__ sepal width of the iris in cm\n",
    "- __petal length__ petal length of the iris in cm\n",
    "- __petal width__ petal width of the iris in cm\n",
    "- __species__ species of the iris (0 = setosa; 1 = versicolor; 2 = virginica)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eb7a24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()\n",
    "df_iris = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df_iris['species'] = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6b8320e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   species  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2781b4",
   "metadata": {},
   "source": [
    "## Load dataset: wine dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d0c8f5",
   "metadata": {},
   "source": [
    "The third dataset is the [wine dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine) from sklearn. It contains the follwing information:\n",
    "- 13 features\n",
    "- 3 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e3a2b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "df_wine = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df_wine['class'] = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b62e54f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  class  \n",
       "0                          3.92   1065.0      0  \n",
       "1                          3.40   1050.0      0  \n",
       "2                          3.17   1185.0      0  \n",
       "3                          3.45   1480.0      0  \n",
       "4                          2.93    735.0      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# needs no prepocessing\n",
    "df_wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af607c5",
   "metadata": {},
   "source": [
    "## Load dataset: covertype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1b9945",
   "metadata": {},
   "source": [
    "The fourth dataset is the [covertype dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html) from sklearn. It contains the follwing information:\n",
    "- 54 features\n",
    "- 7 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cce614ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = fetch_covtype()\n",
    "df_covtype = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df_covtype['type'] = pd.Series(data.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1890dbfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type_31</th>\n",
       "      <th>Soil_Type_32</th>\n",
       "      <th>Soil_Type_33</th>\n",
       "      <th>Soil_Type_34</th>\n",
       "      <th>Soil_Type_35</th>\n",
       "      <th>Soil_Type_36</th>\n",
       "      <th>Soil_Type_37</th>\n",
       "      <th>Soil_Type_38</th>\n",
       "      <th>Soil_Type_39</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>510.0</td>\n",
       "      <td>221.0</td>\n",
       "      <td>232.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>6279.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>6225.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>268.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6121.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3090.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>6211.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>6172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0     2596.0    51.0    3.0                             258.0   \n",
       "1     2590.0    56.0    2.0                             212.0   \n",
       "2     2804.0   139.0    9.0                             268.0   \n",
       "3     2785.0   155.0   18.0                             242.0   \n",
       "4     2595.0    45.0    2.0                             153.0   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                             0.0                            510.0   \n",
       "1                            -6.0                            390.0   \n",
       "2                            65.0                           3180.0   \n",
       "3                           118.0                           3090.0   \n",
       "4                            -1.0                            391.0   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0          221.0           232.0          148.0   \n",
       "1          220.0           235.0          151.0   \n",
       "2          234.0           238.0          135.0   \n",
       "3          238.0           238.0          122.0   \n",
       "4          220.0           234.0          150.0   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type_31  Soil_Type_32  \\\n",
       "0                              6279.0  ...           0.0           0.0   \n",
       "1                              6225.0  ...           0.0           0.0   \n",
       "2                              6121.0  ...           0.0           0.0   \n",
       "3                              6211.0  ...           0.0           0.0   \n",
       "4                              6172.0  ...           0.0           0.0   \n",
       "\n",
       "   Soil_Type_33  Soil_Type_34  Soil_Type_35  Soil_Type_36  Soil_Type_37  \\\n",
       "0           0.0           0.0           0.0           0.0           0.0   \n",
       "1           0.0           0.0           0.0           0.0           0.0   \n",
       "2           0.0           0.0           0.0           0.0           0.0   \n",
       "3           0.0           0.0           0.0           0.0           0.0   \n",
       "4           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "   Soil_Type_38  Soil_Type_39  type  \n",
       "0           0.0           0.0     5  \n",
       "1           0.0           0.0     5  \n",
       "2           0.0           0.0     2  \n",
       "3           0.0           0.0     2  \n",
       "4           0.0           0.0     5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# needs no prepocessing\n",
    "df_covtype.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b60b9b8",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91547430",
   "metadata": {},
   "source": [
    "There are a variety of machine learning models. Now we want to present the most common models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc17b9",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82289a3f",
   "metadata": {},
   "source": [
    "A decision tree is one of the most simple models. Every node represents a logical rule (e.g. is feature smaller than a certain threshold). Depending on the values of the feature of the sample that is used to be classified, we look at the left or right child node. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bcfcb9",
   "metadata": {},
   "source": [
    "<img src=\"../images/decision_tree2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca5da22",
   "metadata": {},
   "source": [
    "With the DataFactory, we can select a model (e.g. a decision tree for classification) and finetune this model to achieve the best results. The algorithm builds multiple decision trees with different parameters. At the end it returns the decision tree with the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53602b",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179825fa",
   "metadata": {},
   "source": [
    "A random forest consists of multiple different decision trees. The finale prediction is the average over the predictions of the decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c870bb8",
   "metadata": {},
   "source": [
    "<img src=\"../images/random_forest.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c5e723",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b5fb16",
   "metadata": {},
   "source": [
    "Like random forest, AdaBoost uses multiple decision trees to make a prediction. But when building the decision tree, the new tree is based on the previous tree. It focuses on the samples which are predicted badly by the previous tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fb9b1",
   "metadata": {},
   "source": [
    "<img src=\"../images/adaboost.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b230976",
   "metadata": {},
   "source": [
    "### GBDT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a1305",
   "metadata": {},
   "source": [
    "Also Gradient Boosting Decision Tree (GBDT) uses multiple decision trees. But instead of averaging the predictions of the trees, their preditctions are summed. So a decision tree predicts the error of the previous tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113bdcc4",
   "metadata": {},
   "source": [
    "<img src=\"../images/gbdt.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d97098",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b4e77",
   "metadata": {},
   "source": [
    "To classify a sample with the K-Nearest Neighbour (KNN) algorithm, we look in the proximity of the sample. So we examine what is the most frequent class of the k neigbours. The sample is then assigned to this class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33298620",
   "metadata": {},
   "source": [
    "<img src=\"../images/knn.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657fdb21",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b9bfd2",
   "metadata": {},
   "source": [
    "The Support Vector Machine (SVM) creates a hyper-plane to segregate the samples of a class. To find the best hyper-plane it tries to maximaize the the distances between nearest sample of either class. If it can't find a plane, it introduces an additional feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f1c00",
   "metadata": {},
   "source": [
    "<img src=\"../images/svm.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e22dcab",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad040c4e",
   "metadata": {},
   "source": [
    "A neural network, also called multi layer perceptron, is one of the most powerful models. It consits of one input layer, one output layer and one or multiple hidden layers in between. Each layer consists of neurons that are connected with the previous layer by edges. After giving the data into the input layer it passes the network to the output node. If the data reaches an edge it is weighted with weight. If the data reaches a node, a bias is added to the data and an 'activation' function is applied. The output layer outputs the prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9e68c",
   "metadata": {},
   "source": [
    "<img src=\"../images/neural_network.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f861e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO add NN to datafactory\n",
    "#model = keras.Sequential(\n",
    "#    [\n",
    "#        layers.Dense(9, kernel_initializer = 'uniform', input_dim=X_train.shape[1], activation='relu'),\n",
    "#        layers.Dropout(0.2),\n",
    "#        layers.Dense(9, kernel_initializer = 'uniform', activation='relu'),\n",
    "#        layers.Dropout(0.2),\n",
    "#        layers.Dense(5, kernel_initializer = 'uniform', activation='relu'),\n",
    "#        layers.Dropout(0.2),\n",
    "#        layers.Dense(1, kernel_initializer = 'uniform', activation='relu'),\n",
    "#    ]\n",
    "#)\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5bedea80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "#training = model.fit(X_train, y_train, epochs=200, batch_size=64, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4c52fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_acc = model.evaluate(X_test, y_test, batch_size=64, verbose=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32fd2940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12abee38",
   "metadata": {},
   "source": [
    "We can see that the accuracy of the neural network is wore then of the other models. Even though, neural networks are more powerful, but if they are applied to too simple problems it might lead to a worse performance then more simple models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf82b33d",
   "metadata": {},
   "source": [
    "## Comparison of the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4039fb3e",
   "metadata": {},
   "source": [
    "Not every model fits for every problem. Here we can see the F1 scores for several models on different datasets. \n",
    "\n",
    "The F1 score is the harmonic mean of the precision and the recall: \n",
    "$$F1 = 2 * \\frac{precision * recall}{precision + recall}$$\n",
    "The higher the F1 score, the better the prediction. Precision and recall are defined as:\n",
    "\n",
    "$$Precision = \\frac{TP}{TP + FP}, Recall = \\frac{TP}{TP + FN}$$\n",
    "TP: True Positive, FN: False Negative, FP: False Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6f7671",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 18:39:20,769 - DataFactory - INFO - Remove columns with NAN-values of target feature: survived\n",
      "2021-11-16 18:39:20,773 - DataFactory - INFO - Start to transform the categorical columns...\n",
      "2021-11-16 18:39:20,777 - DataFactory - INFO - Start with one-hot encoding of the following categoric features: ['sex', 'embarked']...\n",
      "2021-11-16 18:39:20,780 - DataFactory - INFO - ...End with one-hot encoding\n",
      "2021-11-16 18:39:20,780 - DataFactory - INFO - Start label encoding of the following categoric features: ['name', 'ticket', 'cabin', 'boat', 'home.dest']...\n",
      "2021-11-16 18:39:20,787 - DataFactory - INFO - ...End with label encoding\n",
      "2021-11-16 18:39:20,789 - DataFactory - INFO - ...End with categorical feature transformation\n",
      "2021-11-16 18:39:20,790 - DataFactory - INFO - Start to clean the given dataframe...\n",
      "2021-11-16 18:39:20,794 - DataFactory - INFO - Number of INF- and NAN-values are: (0, 952)\n",
      "2021-11-16 18:39:20,794 - DataFactory - INFO - Set type to float32 at first && deal with INF\n",
      "2021-11-16 18:39:20,797 - DataFactory - INFO - Remove columns with half of NAN-values\n",
      "2021-11-16 18:39:20,799 - DataFactory - INFO - Remove constant columns\n",
      "2021-11-16 18:39:20,802 - DataFactory - INFO - Start to fill the columns with NAN-values...\n",
      "2021-11-16 18:39:20,916 - DataFactory - INFO - ...End with Data cleaning, number of INF- and NAN-values are now: (0, 0)\n",
      "2021-11-16 18:39:20,916 - DataFactory - INFO - Start search for best parameters of: decision_tree...\n",
      "2021-11-16 18:39:22,815 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:39:22,815 - DataFactory - INFO - Best parameters are: {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 3, 'criterion': 'gini'} with score 0.97\n",
      "2021-11-16 18:39:22,816 - DataFactory - INFO - Start search for best parameters of: random_forest...\n",
      "2021-11-16 18:39:25,016 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:39:25,017 - DataFactory - INFO - Best parameters are: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 20} with score 0.97\n",
      "2021-11-16 18:39:25,017 - DataFactory - INFO - Start search for best parameters of: adaboost...\n",
      "2021-11-16 18:39:27,068 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:39:27,068 - DataFactory - INFO - Best parameters are: {'n_estimators': 50, 'learning_rate': 0.001} with score 0.98\n",
      "2021-11-16 18:39:27,069 - DataFactory - INFO - Start search for best parameters of: gbdt...\n",
      "2021-11-16 18:39:29,726 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:39:29,727 - DataFactory - INFO - Best parameters are: {'min_samples_leaf': 1, 'max_depth': 1, 'learning_rate': 0.01} with score 0.97\n",
      "2021-11-16 18:39:29,728 - DataFactory - INFO - Start search for best parameters of: svm...\n",
      "2021-11-16 18:42:39,156 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:39,156 - DataFactory - INFO - Best parameters are: {'kernel': 'linear', 'gamma': 0.1, 'C': 10} with score 0.95\n",
      "2021-11-16 18:42:39,157 - DataFactory - INFO - Start search for best parameters of: knn...\n",
      "2021-11-16 18:42:39,296 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:39,297 - DataFactory - INFO - Best parameters are: {'weights': 'distance', 'n_neighbors': 26} with score 0.67\n",
      "2021-11-16 18:42:39,300 - DataFactory - INFO - Remove columns with NAN-values of target feature: species\n",
      "2021-11-16 18:42:39,302 - DataFactory - INFO - Start to transform the categorical columns...\n",
      "2021-11-16 18:42:39,305 - DataFactory - INFO - ...End with categorical feature transformation\n",
      "2021-11-16 18:42:39,306 - DataFactory - INFO - Start to clean the given dataframe...\n",
      "2021-11-16 18:42:39,307 - DataFactory - INFO - Number of INF- and NAN-values are: (0, 0)\n",
      "2021-11-16 18:42:39,308 - DataFactory - INFO - Set type to float32 at first && deal with INF\n",
      "2021-11-16 18:42:39,308 - DataFactory - INFO - Remove columns with half of NAN-values\n",
      "2021-11-16 18:42:39,310 - DataFactory - INFO - Remove constant columns\n",
      "2021-11-16 18:42:39,313 - DataFactory - INFO - ...End with Data cleaning, number of INF- and NAN-values are now: (0, 0)\n",
      "2021-11-16 18:42:39,314 - DataFactory - INFO - Start search for best parameters of: decision_tree...\n",
      "2021-11-16 18:42:39,372 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:39,373 - DataFactory - INFO - Best parameters are: {'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 6, 'criterion': 'entropy'} with score 0.97\n",
      "2021-11-16 18:42:39,373 - DataFactory - INFO - Start search for best parameters of: random_forest...\n",
      "2021-11-16 18:42:40,823 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:40,824 - DataFactory - INFO - Best parameters are: {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_depth': 20} with score 0.95\n",
      "2021-11-16 18:42:40,825 - DataFactory - INFO - Start search for best parameters of: adaboost...\n",
      "2021-11-16 18:42:42,132 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:42,133 - DataFactory - INFO - Best parameters are: {'n_estimators': 50, 'learning_rate': 0.01} with score 0.92\n",
      "2021-11-16 18:42:42,134 - DataFactory - INFO - Start search for best parameters of: gbdt...\n",
      "2021-11-16 18:42:44,218 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:44,219 - DataFactory - INFO - Best parameters are: {'min_samples_leaf': 2, 'max_depth': 1, 'learning_rate': 0.01} with score 0.97\n",
      "2021-11-16 18:42:44,220 - DataFactory - INFO - Start search for best parameters of: svm...\n",
      "2021-11-16 18:42:44,324 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:44,325 - DataFactory - INFO - Best parameters are: {'kernel': 'linear', 'gamma': 1, 'C': 10} with score 0.92\n",
      "2021-11-16 18:42:44,325 - DataFactory - INFO - Start search for best parameters of: knn...\n",
      "2021-11-16 18:42:44,391 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:44,391 - DataFactory - INFO - Best parameters are: {'weights': 'distance', 'n_neighbors': 21} with score 0.97\n",
      "2021-11-16 18:42:44,394 - DataFactory - INFO - Remove columns with NAN-values of target feature: class\n",
      "2021-11-16 18:42:44,396 - DataFactory - INFO - Start to transform the categorical columns...\n",
      "2021-11-16 18:42:44,399 - DataFactory - INFO - ...End with categorical feature transformation\n",
      "2021-11-16 18:42:44,400 - DataFactory - INFO - Start to clean the given dataframe...\n",
      "2021-11-16 18:42:44,401 - DataFactory - INFO - Number of INF- and NAN-values are: (0, 0)\n",
      "2021-11-16 18:42:44,402 - DataFactory - INFO - Set type to float32 at first && deal with INF\n",
      "2021-11-16 18:42:44,403 - DataFactory - INFO - Remove columns with half of NAN-values\n",
      "2021-11-16 18:42:44,404 - DataFactory - INFO - Remove constant columns\n",
      "2021-11-16 18:42:44,408 - DataFactory - INFO - ...End with Data cleaning, number of INF- and NAN-values are now: (0, 0)\n",
      "2021-11-16 18:42:44,408 - DataFactory - INFO - Start search for best parameters of: decision_tree...\n",
      "2021-11-16 18:42:44,469 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:44,470 - DataFactory - INFO - Best parameters are: {'min_samples_split': 3, 'min_samples_leaf': 4, 'max_depth': 4, 'criterion': 'entropy'} with score 0.96\n",
      "2021-11-16 18:42:44,470 - DataFactory - INFO - Start search for best parameters of: random_forest...\n",
      "2021-11-16 18:42:46,219 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:46,219 - DataFactory - INFO - Best parameters are: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_depth': 10} with score 0.98\n",
      "2021-11-16 18:42:46,220 - DataFactory - INFO - Start search for best parameters of: adaboost...\n",
      "2021-11-16 18:42:47,605 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:47,605 - DataFactory - INFO - Best parameters are: {'n_estimators': 50, 'learning_rate': 0.1} with score 1.00\n",
      "2021-11-16 18:42:47,606 - DataFactory - INFO - Start search for best parameters of: gbdt...\n",
      "2021-11-16 18:42:51,681 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:51,682 - DataFactory - INFO - Best parameters are: {'min_samples_leaf': 1, 'max_depth': 20, 'learning_rate': 0.1} with score 0.91\n",
      "2021-11-16 18:42:51,683 - DataFactory - INFO - Start search for best parameters of: svm...\n",
      "2021-11-16 18:42:52,032 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:52,033 - DataFactory - INFO - Best parameters are: {'kernel': 'linear', 'gamma': 0.1, 'C': 10} with score 0.93\n",
      "2021-11-16 18:42:52,034 - DataFactory - INFO - Start search for best parameters of: knn...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 18:42:52,103 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:42:52,103 - DataFactory - INFO - Best parameters are: {'weights': 'uniform', 'n_neighbors': 14} with score 0.77\n",
      "2021-11-16 18:42:52,561 - DataFactory - INFO - Remove columns with NAN-values of target feature: type\n",
      "2021-11-16 18:42:52,733 - DataFactory - INFO - Start to transform the categorical columns...\n",
      "2021-11-16 18:42:52,809 - DataFactory - INFO - ...End with categorical feature transformation\n",
      "2021-11-16 18:42:52,827 - DataFactory - INFO - Start to clean the given dataframe...\n",
      "2021-11-16 18:42:52,939 - DataFactory - INFO - Number of INF- and NAN-values are: (0, 0)\n",
      "2021-11-16 18:42:52,939 - DataFactory - INFO - Set type to float32 at first && deal with INF\n",
      "2021-11-16 18:42:53,420 - DataFactory - INFO - Remove columns with half of NAN-values\n",
      "2021-11-16 18:42:53,528 - DataFactory - INFO - Remove constant columns\n",
      "2021-11-16 18:42:53,725 - DataFactory - INFO - ...End with Data cleaning, number of INF- and NAN-values are now: (0, 0)\n",
      "2021-11-16 18:42:53,761 - DataFactory - INFO - Start search for best parameters of: decision_tree...\n",
      "2021-11-16 18:43:18,175 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:43:18,176 - DataFactory - INFO - Best parameters are: {'min_samples_split': 8, 'min_samples_leaf': 1, 'max_depth': 8, 'criterion': 'gini'} with score 0.73\n",
      "2021-11-16 18:43:18,187 - DataFactory - INFO - Start search for best parameters of: random_forest...\n",
      "2021-11-16 18:59:21,860 - DataFactory - INFO - ...End search\n",
      "2021-11-16 18:59:21,860 - DataFactory - INFO - Best parameters are: {'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_depth': 50} with score 0.95\n",
      "2021-11-16 18:59:21,872 - DataFactory - INFO - Start search for best parameters of: adaboost...\n",
      "2021-11-16 19:12:36,929 - DataFactory - INFO - ...End search\n",
      "2021-11-16 19:12:36,930 - DataFactory - INFO - Best parameters are: {'n_estimators': 100, 'learning_rate': 0.001} with score 0.64\n",
      "2021-11-16 19:12:37,059 - DataFactory - INFO - Start search for best parameters of: gbdt...\n",
      "2021-11-16 19:26:57,562 - DataFactory - INFO - ...End search\n",
      "2021-11-16 19:26:57,563 - DataFactory - INFO - Best parameters are: {'min_samples_leaf': 1, 'max_depth': 50, 'learning_rate': 0.1} with score 0.82\n",
      "2021-11-16 19:26:57,575 - DataFactory - INFO - Start search for best parameters of: svm...\n"
     ]
    }
   ],
   "source": [
    "results = compare_models(['decision_tree', 'random_forest', 'adaboost', 'gbdt', 'svm', 'knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0a6be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datafactory",
   "language": "python",
   "name": "datafactory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

#pre_processing
## What is preprecessing and why do we need it
数据的质量，直接决定了模型的预测和泛化能力的好坏。它涉及很多因素，包括：准确性、完整性、一致性、时效性、可信性和解释性。而在真实数据中，我们拿到的数据可能包含了大量的缺失值，可能包含大量的噪音，也可能因为人工录入错误导致有异常点存在，非常不利于算法模型的训练。数据清洗的结果是对各种脏数据进行对应方式的处理，得到标准的、干净的、连续的数据，提供给数据统计、数据挖掘等使用。
## Common data pre-processing methods
### 数据导入
介绍导入要注意的问题
### 数据审核
  准确性审核：比如数据不一致，比如岁数和出生年不一致
  实用性审核：比如数据冗余，包含很多不需要的属性
  实时性审核
### 数据清理
数据清理(data cleaning) 的主要思想是通过填补缺失值、光滑噪声数据，平滑或删除离群点，并解决数据的不一致性来“清理“数据。如果客户认为数据是脏乱的，他们不太会相信基于这些数据的挖掘结果，即输出的结果是不可靠的§
不同的数据集，存在的问题可能不同。这里针对一些经典的问题进行处理：
#### 字符数据处理

#### 时间数据处理

#### 重复数据
####  缺失值处理，
##### 原因 造成的原因是多种多样的
##### 方法
    删除变量：如果一个变量的缺失率比较高（80%），且重要性比较低，则可以直接删掉变量
    填充缺失：根据填充的值的不同又分为定值和统计值填充
    插值法填充：包括随机插值，多重差补法，热平台插补，拉格朗日插值，牛顿插值等
    模型填充：使用回归、贝叶斯、随机森林、决策树等模型对缺失数据进行预测
    哑变量填充
#### 离群点处理
##### 原因
异常值是数据分布的常态，处于特定分布区域或范围之外的数据通常被定义为异常或噪声。异常分为两种：“伪异常”，由于特定的业务运营动作产生，是正常反应业务的状态，而不是数据本身的异常；“真异常”，不是由于特定的业务运营动作产生，而是数据本身分布异常，即离群点。主要有以下检测离群点的方法：
##### 检测方法
    3 sigma
    基于绝对离差中位数（MAD）
    基于距离（计算复杂度高）
    基于密度
    基于聚类
##### 处理方法
    根据异常点的数量和影响考虑是否删除记录-》信息损失多
    log scale
    平均值或中位值替代异常值
    选择对异常值鲁棒性较高的模型，比如决策树
#### 噪音
噪声是变量的随机误差和方差，是观测点和真实点之间的误差，即 [公式] 。通常的处理办法：对数据进行分箱操作，等频或等宽分箱，然后用每个箱的平均数，中位数或者边界值（不同数据分布，处理方法不同）代替箱中所有的数，起到平滑数据的作用。另外一种做法是，建立该变量和预测变量的回归模型，根据回归系数和预测变量，反解出自变量的近似值。
### 数据平衡
### 数据集成
### 数据变换
规范化处理：mimmax,zscore, log, Box-Cox 
离散化处理：等频，等宽(Discretization)，聚类
稀疏化处理：onehot
### 数据平衡
预测类平衡
属性平衡
### 属性工程

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38e4cdb8",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/sdsc-bw/DataFactory/blob/develop/demos/03_Model_Selection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b807f0b1",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00f1464",
   "metadata": {},
   "source": [
    "There is a variety of models that can be used in machine learning like decision trees, random forests, neural networks...\n",
    "Depending on the problem we have many different models to choose from. Here a small overview of the most common:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8988103f",
   "metadata": {},
   "source": [
    "<img src=\"../images/model_selection.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9961a5ac",
   "metadata": {},
   "source": [
    "If have labeled training data we can choose between different many different supervised methods. Whereas if we don't have the labels, the we have to use unsupervised methods like clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf3fa2",
   "metadata": {},
   "source": [
    "Also according to the problem, some models fit better than others. For example, for a simple problem it makes sense to use a more simple model like a decision tree, because more complex models like neural networks can lead to overfitting. Whereas these complexe models perform better at non-linear problems. In this notebook we want to show some models and how they perform on different tasks. \n",
    "\n",
    "In this notebook we want to introduce Time Series (TS) and some state-of-the-art architectures. A time series is a series/list of data points in time order. A simple example is be the temperature measurement over one day."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3552c90",
   "metadata": {},
   "source": [
    "<img src=\"../images/ts.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057abe2d",
   "metadata": {},
   "source": [
    "Time series in AI can be divided in 2 tasks:\n",
    "- Classification: asign the series to one class (sometimes multiple)\n",
    "- Regression/Forecasting: use time series to predict future values\n",
    "\n",
    "There are a variety of state-of-the-art architectures to solve these tasks. In this repo we provide a simple interface to train common architectures (and later to finetune them). In order to do that we use the library [tsai](https://github.com/timeseriesAI/tsai) which provides state-of-the-art techniques for time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7c093e",
   "metadata": {},
   "source": [
    "# Introduction of Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91547430",
   "metadata": {},
   "source": [
    "There are a variety of machine learning models. Now we want to present the most common models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc17b9",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82289a3f",
   "metadata": {},
   "source": [
    "A decision tree is one of the most simple models. Every node represents a logical rule (e.g. is feature smaller than a certain threshold). Depending on the values of the feature of the sample that is used to be classified, we look at the left or right child node. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bcfcb9",
   "metadata": {},
   "source": [
    "<img src=\"../images/decision_tree2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca5da22",
   "metadata": {},
   "source": [
    "With the DataFactory, we can select a model (e.g. a decision tree for classification) and finetune this model to achieve the best results. The algorithm builds multiple decision trees with different parameters. At the end it returns the decision tree with the best score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53602b",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179825fa",
   "metadata": {},
   "source": [
    "A random forest consists of multiple different decision trees. The finale prediction is the average over the predictions of the decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c870bb8",
   "metadata": {},
   "source": [
    "<img src=\"../images/random_forest.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c5e723",
   "metadata": {},
   "source": [
    "### Adaptive Boosting (AdaBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b5fb16",
   "metadata": {},
   "source": [
    "Like random forest, AdaBoost uses multiple decision trees to make a prediction. But when building the decision tree, the new tree is based on the previous tree. It focuses on the samples which are predicted badly by the previous tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2fb9b1",
   "metadata": {},
   "source": [
    "<img src=\"../images/adaboost.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b230976",
   "metadata": {},
   "source": [
    "### Gradient Boosting Decision Tree (GBDT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a1305",
   "metadata": {},
   "source": [
    "Also Gradient Boosting Decision Tree (GBDT) uses multiple decision trees. But instead of averaging the predictions of the trees, their preditctions are summed. So a decision tree predicts the error of the previous tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113bdcc4",
   "metadata": {},
   "source": [
    "<img src=\"../images/gbdt.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d97098",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbour (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39b4e77",
   "metadata": {},
   "source": [
    "To classify a sample with the K-Nearest Neighbour (KNN) algorithm, we look in the proximity of the sample. So we examine what is the most frequent class of the k neigbours. The sample is then assigned to this class. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33298620",
   "metadata": {},
   "source": [
    "<img src=\"../images/knn.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657fdb21",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b9bfd2",
   "metadata": {},
   "source": [
    "The Support Vector Machine (SVM) creates a hyper-plane to segregate the samples of a class. To find the best hyper-plane it tries to maximaize the the distances between nearest sample of either class. If it can't find a plane, it introduces an additional feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30f1c00",
   "metadata": {},
   "source": [
    "<img src=\"../images/svm.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e22dcab",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad040c4e",
   "metadata": {},
   "source": [
    "A neural network, also called multi layer perceptron, is one of the most powerful models. It consits of one input layer, one output layer and one or multiple hidden layers in between. Each layer consists of neurons that are connected with the previous layer by edges. After giving the data into the input layer it passes the network to the output node. If the data reaches an edge it is weighted with weight. If the data reaches a node, a bias is added to the data and an 'activation' function is applied. The output layer outputs the prediction.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9e68c",
   "metadata": {},
   "source": [
    "<img src=\"../images/neural_network.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12abee38",
   "metadata": {},
   "source": [
    "Sometimes the performance of the neural network is worse then them of the other models. Even though, neural networks are more powerful, but if they are applied to too simple problems it might lead to overfitting. Therefor the model selection is very important. \n",
    "\n",
    "There are some basic layers and functions that are used in neural networks. We will briefly introduce them now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d32c65",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf9a3c3",
   "metadata": {},
   "source": [
    "#### Fully Connected Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4f94a",
   "metadata": {},
   "source": [
    "In a fully connected layer has every neurona on the previous layer a connection to every neuron in the following layer. A standard neural network consists mainly of this layers. In an convolutional neural network they are in general at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef3d51b",
   "metadata": {},
   "source": [
    "<img src=\"../images/fc.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a20915",
   "metadata": {},
   "source": [
    "#### Convolutional Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e86f583",
   "metadata": {},
   "source": [
    "Convolutional layer apply a filter/kernel on a matrix of values. The kernel is shifted over the matrix in a certain step size (stride). In each step each value of the kernel is multiplied with the value of the matrix where it layes above. At the end these values are summed to a entry in a new matrix. In general the output is smaller than the input, but we can add a padding to maintain the input size. During training learns the convolutional layer the values of the kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81e0eb5",
   "metadata": {},
   "source": [
    "<img src=\"../images/convolution.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6476a6e1",
   "metadata": {},
   "source": [
    "#### Pooling Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699bc0dc",
   "metadata": {},
   "source": [
    "The mostly used pooling layer is the max pooling layer. It normally follows after a convolutional layer and an activation function. There is also some kind of kernel (normally 2x2 and stride=2) that shifts over the image and finds the maximum value in the area where it is applied to."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8963fefa",
   "metadata": {},
   "source": [
    "<img src=\"../images/pooling.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee27d287",
   "metadata": {},
   "source": [
    "#### Inception Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42abadb2",
   "metadata": {},
   "source": [
    "A inception layer deploys multiple convolutions with multiple kernels and pooling layers simultaneously in parallel. At the it concatinates the autput of the different operations. It is more computational expensive but allows better learning of useful features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06667d33",
   "metadata": {},
   "source": [
    "<img src=\"../images/inception.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d7f7fb",
   "metadata": {},
   "source": [
    "#### Batch Normalization Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c037d4",
   "metadata": {},
   "source": [
    "Batch normalization is used to make a neural network faster and more stable. It rescales or recenters the input of this layer. It maintains the mean of the output close to 0 and the strandard devation of the output close to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ca7cf9",
   "metadata": {},
   "source": [
    "#### Dropout Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996035b7",
   "metadata": {},
   "source": [
    "A dropout layer is used to decrease the risk of overfitting. During training it drops out (turn off) randomly a defined percentage of neurons. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21c805c",
   "metadata": {},
   "source": [
    "<img src=\"../images/dropout.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdf530b",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1fadae2",
   "metadata": {},
   "source": [
    "An activation function of a node is applied on the ouput of that node. Neural networks are able to solve complex problems because in general they use non-linear activation functions. Common functions are:\n",
    "- ReLU\n",
    "- Tanh\n",
    "- Sigmoid (today hardly used)\n",
    "- Softmax (commonly after last layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea0ac26",
   "metadata": {},
   "source": [
    "### Comon Architectures\n",
    "\n",
    "#### MLP\n",
    "The MLP was proposed from Wang et al. in 2016 ([paper](https://arxiv.org/abs/1611.06455)). It stacks three fully-connected layers. Each layer conists of 500 neurons and is followed by a dropout layer and a ReLU function. It ends with a softmax layer.\n",
    "\n",
    "<img src=\"../images/mlp.png\"/>\n",
    "\n",
    "#### ResNet\n",
    "ResNet was proposed from Wang et al. in 2016 ([paper](https://arxiv.org/abs/1611.06455)). It consists of three residual blocks. Each block consits of three convolutional layers each followed by batch normalization and a ReLU function. Also there is a shortcut in every residual block. At the end is a global average pooling layer and a softmax layer.\n",
    "\n",
    "<img src=\"../images/res_net.png\"/>\n",
    "\n",
    "#### IncetptionTime\n",
    "InceptionTime was propsed from Fawaz et al. in 2019 ([paper](https://arxiv.org/abs/1909.04939)). Compared to ResNet, InceptionTime has three inception blocks instead of convolutional layer.\n",
    "\n",
    "<img src=\"../images/inception_time.png\"/>\n",
    "\n",
    "#### MiniRocket\n",
    "MiniRocket was proposed from Dempster et al. in 2021 ([paper](https://arxiv.org/abs/2102.00457)). In contrast to the other methods is that it is a linear classifier. It transforms the input TS with random convolutional kernels and uses the transformed features to train the linear classifier. As a consequence it is less accurate then the other state-of-the-art-methods, but much faster to train."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datafactory",
   "language": "python",
   "name": "datafactory"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
